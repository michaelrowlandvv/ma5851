{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPqe4YRcPEcIsF/9ZhjZVK7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Install and import dependencies"],"metadata":{"id":"80dr0QaHiVqE"}},{"cell_type":"code","source":["!pip install snscrape\n","import snscrape.modules.twitter as sntwitter\n","import pandas as pd"],"metadata":{"id":"gcWK760WZ9kb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helper Functions"],"metadata":{"id":"lHYRmW3MjKqF"}},{"cell_type":"code","source":["#returns True if the one if the elements in inlist is in the string s\n","def StringinList(inlist, s):\n","  for item in inlist:\n","    if item.lower() in s.lower():\n","      return True\n","  return False\n","\n","#extracts hastags from a string\n","def GetHashtags(inString):\n","  outlist=[]\n","  ss=instring.split()\n","  for s in ss:\n","    if s.startswith(\"#\"):\n","      outlist.append(s)\n","  return outlist\n","\n","#appends the tweet to the attribute container\n","def AppendToContainer(incontainer, tweet):\n","  incontainer.append([tweet.id, tweet.conversationId, tweet.user.id, tweet.user.rawDescription, tweet.user.followersCount, \n","                                 tweet.user.friendsCount, \n","                                 tweet.user.location, tweet.retweetCount, tweet.viewCount, \n","                                 tweet.date.timestamp(),tweet.date.strftime('%Y-%m-%d %H:%M:%S'), \n","                                 tweet.likeCount, tweet.sourceLabel, tweet.rawContent, tweet.vibe ])\n"],"metadata":{"id":"XOK-DLSBjI7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attributes_container=[]\n","numberretrieved = 0\n","searchterms = [\"republic \", \"monarch\"]\n","initialquery = '(#AusPol) since:2021-01-01'\n","hashtagdict={}\n","for i,tweet in enumerate(sntwitter.TwitterSearchScraper(initialquery).get_items()):\n","    if StringinList(searchterms, tweet.rawContent):\n","      attributes_container.attributes_container.AppendToContainer(tweet)\n","      hashtaglist=GetHashtags(tweet.rawContent)\n","      for h in hashtaglist:\n","        hl = GetHashtags(h)\n","        if hashtagdict.keys.contains(hl):\n","          hashtagdict.update({hl: hashtagdict[hl]+1}) \n","        else:\n","          hashtagdict[hl]=1\n","    numberretrieved+=1\n","    if numberretrieved % 100 == 0:\n","      time.sleep(0.5)\n","      print(numberretrieved)\n","      if numberretrieved>20000:\n","        break\n"," \n"],"metadata":{"id":"mzMBOUujqbMy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Add to container list based on other hashtags\n"],"metadata":{"id":"HjK2KNf5kCLD"}},{"cell_type":"code","source":["sortedhashtages = {k: v for k, v in sorted(hashtagdict.items(), key=lambda item: -item[1])}\n","listhashtags = list(sortedhashtages.keys())[0:3]\n","for h in listhashtags:\n","  query = '(' + h + ') since:2021-01-01'\n","  for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n","    if StringinList(searchterms, tweet.rawContent):\n","      attributes_container.attributes_container.AppendToContainer(tweet)"],"metadata":{"id":"nQuTRau8kbe6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create a Dataframe and save"],"metadata":{"id":"8BSFV_H7jwEl"}},{"cell_type":"code","source":["tweets_df = pd.DataFrame(attributes_container, columns=[\"ID\", \"ConversationID\", \"UserId\", \"UserDescription\", \"FollowersCount\",  \"FriendsCount\", \"Location\", \"Retweets\", \"ViewCount\", \"EpochTime\",\"UTCTime\" ,\"Likes\", \"Source\", \"Content\", \"Vibe\", ])\n","tweets_df.to_excel(\"/content/drive/MyDrive/A3/TweetsBackup.xlsx\")"],"metadata":{"id":"nqPEECpUjsIV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#tweets_df.to_excel(\"/content/drive/MyDrive/A3/AusRepublic.xlsx\")\n","tweets_df.to_excel(\"/content/drive/MyDrive/A3/TweetsBackup.xlsx\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KWWM-oYnWe8g","executionInfo":{"status":"ok","timestamp":1682034314500,"user_tz":-600,"elapsed":22981,"user":{"displayName":"Hey Boo","userId":"02448068063730063578"}},"outputId":"265f342a-db42-4e4e-b210-2673abeec7ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**Data Wrangling**\n","\n","Import dependencies"],"metadata":{"id":"v69QN6vj2YAu"}},{"cell_type":"code","source":["import pandas as pd\n","import nltk\n","import pandas as pd\n","import numpy as np\n","import json\n","import re\n","import matplotlib.pyplot as plt \n","import seaborn as sns\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","#from tqdm import tqdm\n","#from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from nltk.corpus import stopwords\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OyDGzbJooHaC","executionInfo":{"status":"ok","timestamp":1682383492156,"user_tz":-600,"elapsed":4638,"user":{"displayName":"Hey Boo","userId":"02448068063730063578"}},"outputId":"66ba1198-f2fa-4c0b-875e-27a86f3a6d68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","#concatenate all workbooks\n","df1 = pd.read_excel(\"/content/drive/MyDrive/A3/AuspolRoyal.xlsx\")\n","df2 = pd.read_excel(\"/content/drive/MyDrive/A3/AusRepublic.xlsx\")\n","df3 = pd.read_excel(\"/content/drive/MyDrive/A3/AuspolMonarch.xlsx\")\n","df4 = pd.read_excel(\"/content/drive/MyDrive/A3/ConstitutionalMonarchy.xlsx\")\n","df5 = pd.read_excel(\"/content/drive/MyDrive/A3/AuspolRepublic.xlsx\")\n","df6 = pd.read_excel(\"/content/drive/MyDrive/A3/VoteNoRepublic.xlsx\")\n","df = pd.concat([df1, df2, df3, df4, df5, df6])\n","df.to_excel(\"/content/drive/MyDrive/A3/RawData.xlsx\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e-F1xvNn1LNB","executionInfo":{"status":"ok","timestamp":1682042833299,"user_tz":-600,"elapsed":34442,"user":{"displayName":"Hey Boo","userId":"02448068063730063578"}},"outputId":"945a2f67-0d85-4fed-f5ca-7a8590feba24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["Initial Exploration\n","\n","Helper Functions"],"metadata":{"id":"JMdIg9Mc2ubV"}},{"cell_type":"code","source":["#from nltk.corpus import stopwords\n","stopwordsenglish = set(stopwords.words('english'))\n","\n","# function to remove stopwords\n","def removestopwords(text, sw):\n","    no_stopword_text = [w for w in text.split() if not w in sw]\n","    return ' '.join(no_stopword_text)\n","\n","def cleantext(text, sw):\n","    text = re.sub(\"\\'\", \"\", text) \n","    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n","    text = ' '.join(text.split()) \n","    text = text.lower() \n","    text = removestopwords(text, sw)\n","    return text\n","\n","def freq_words(x, terms = 30): \n","  all_words = ' '.join([text for text in x]) \n","  all_words = all_words.split() \n","  fdist = nltk.FreqDist(all_words) \n","  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())}) \n","  \n","  # selecting top 20 most frequent words \n","  d = words_df.nlargest(columns=\"count\", n = terms) \n","  \n","  # visualize words and frequencies\n","  plt.figure(figsize=(12,15)) \n","  ax = sns.barplot(data=d, x= \"count\", y = \"word\") \n","  ax.set(ylabel = 'Word') \n","  plt.show()\n","\n","def uniqueWords(x):\n","  words = ' '.join([text for text in x]) \n","  words = nltk.tokenize.word_tokenize(words)\n","  fdist1 = nltk.FreqDist(words)\n","  freq = dict((word, freq) for word, freq in fdist1.items() if not word.isdigit())\n","  return freq\n"],"metadata":{"id":"fcnJZEuWQoKT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Unique entries prior to processing"],"metadata":{"id":"j_gEyxE06bKn"}},{"cell_type":"code","source":["df.describe()\n","                   \n"],"metadata":{"id":"lRvaXtq8S7Bh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tx(x):\n","  return str(x) + \"A\"\n","\n","#entries\n","numentries= len(uniqueWords(df['Content']).keys())  \n","print (numentries)  #50234  \n","#conversations\n","strc = df['ConversationID'].apply(tx)\n","conversations = uniqueWords(strc)\n","numconversations = len(conversations.keys() )    \n","print(numconversations)     #18389  \n","uconv = freq_words(strc) \n","describe(df)\n"],"metadata":{"id":"47XCCOJr8G4b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Reload backup file"],"metadata":{"id":"QQsFIXKRdfoY"}},{"cell_type":"code","source":["\n","df = pd.read_excel(\"/content/drive/MyDrive/A3/RawData.xlsx\")\n","\n","#clean data\n","print(df.shape[0]) #20501  Unc\n","df.drop_duplicates(subset=['ID'], inplace=True)\n","print(df.shape[0]) #19419\n","#drop the persistent index\n","df.drop(['Unnamed: 0'], axis=1, inplace=True)\n","df['SampleResponse'] = np.nan"],"metadata":{"id":"xH62_9nw4ZR1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Clean Content"],"metadata":{"id":"-qzTauSX5kq5"}},{"cell_type":"code","source":["df['CleanContent'] = df['Content'].apply(lambda x: cleantext(x, stopwordsenglish))"],"metadata":{"id":"Msc2S5xX5hr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_excel(\"/content/drive/MyDrive/A3/RawDatay.xlsx\")\n","print(df.shape[0]) #19419\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVrp4E8nkPKU","executionInfo":{"status":"ok","timestamp":1682074522546,"user_tz":-600,"elapsed":8962,"user":{"displayName":"Hey Boo","userId":"02448068063730063578"}},"outputId":"c72fc323-2771-45ae-a3b7-3172baea82ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["19419\n"]}]}]}